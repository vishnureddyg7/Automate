import requests
import csv
import re
# Replace with your GitHub username and personal access token
GITHUB_USERNAME = "GH User Name"
GITHUB_TOKEN = "Replace your Token"

# GitHub API URL for fetching issues
REPO_OWNER = "urbanpiper"
REPO_NAME = "incidents"
QUERY = "is:issue state:closed 22164886"  # The search query used in GitHub
API_URL = f"https://api.github.com/search/issues?q={QUERY}+repo:{REPO_OWNER}/{REPO_NAME}"

# Headers for authentication
headers = {
    "Accept": "application/vnd.github.v3+json",
    "Authorization": f"token {GITHUB_TOKEN}"
}

# Fetch the data
response = requests.get(API_URL, headers=headers)


# Regex patterns to extract required details
patterns = {
    "issue_reporter": r"Issue Reporter\s*:\s*([\w\s]+) \|",
    "reporter_email": r"Issue Reporter\s*:\s*[\w\s]+ \| ([\w\.\-]+@[\w\.\-]+)",
    "severity": r"Severity\s*:\s*(\S+)",
    "service": r"Service\s*:\s*(\S+)",
    "reporting_team": r"Reporting team\s*:\s*(\S+)",
    "biz_id": r"Biz ID\s*:\s*(\d+)",
    "biz_name": r"Biz Name\s*:\s*(.+)"
}

# Function to extract data using regex
def extract_data(description):
    data = {}
    for key, pattern in patterns.items():
        match = re.search(pattern, description)
        data[key] = match.group(1) if match else "Unknown"
    return data

# Process the response
if response.status_code == 200:
    issues = response.json().get("items", [])
    
    csv_file = "github_issues_report.csv"
    
    with open(csv_file, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        
        # Write header
        writer.writerow([
            "Incident ID", "Issue Reporter", "Reporter Email",
            "Severity", "Service", "Reporting Team",
            "Biz ID", "Biz Name", "Open Time", "Close Time", "Issue URL"
        ])
        
        # Write issue data
        for issue in issues:
            description = issue.get("body", "")  
            extracted_data = extract_data(description)  

            writer.writerow([
                extracted_data["incident_id"],
                extracted_data["issue_reporter"],
                extracted_data["reporter_email"],
                extracted_data["severity"],
                extracted_data["service"],
                extracted_data["reporting_team"],
                extracted_data["biz_id"],
                extracted_data["biz_name"],
                issue["created_at"],
                issue.get("closed_at", "Still Open"),
                issue["html_url"]
            ])
    
    print(f"Data saved successfully in {csv_file}")

else:
    print(f"Error: {response.status_code}, {response.json()}")
